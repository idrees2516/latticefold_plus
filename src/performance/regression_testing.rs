/// Performance Regression Testing Framework
/// 
/// This module implements automated performance regression testing with
/// continuous monitoring, alert generation, and historical trend analysis
/// as specified in task 15.2. The framework provides:
/// 
/// - Automated performance regression detection
/// - Historical performance data management
/// - Alert generation and notification system
/// - Performance trend analysis and forecasting
/// - Integration with CI/CD pipelines for continuous monitoring
/// 
/// The regression testing framework ensures that performance improvements
/// are maintained over time and that any performance degradations are
/// quickly identified and addressed.

use crate::error::{LatticeFoldError, Result};
use std::{
    collections::{HashMap, VecDeque},
    time::{Duration, SystemTime, UNIX_EPOCH},
    fs::{File, OpenOptions},
    io::{Write, BufWriter, BufReader, BufRead},
    path::{Path, PathBuf},
};
use serde::{Serialize, Deserialize};

/// Performance regression testing configuration
/// 
/// Configures the regression testing framework including thresholds,
/// historical data management, alert settings, and monitoring parameters.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RegressionTestConfig {
    /// Performance regression threshold percentage (e.g., 5.0 for 5%)
    pub regression_threshold: f64,
    
    /// Number of historical measurements to maintain for trend analysis
    pub historical_window_size: usize,
    
    /// Minimum number of measurements required for regression detection
    pub minimum_measurements: usize,
    
    /// Statistical confidence level for regression detection (e.g., 0.95 for 95%)
    pub confidence_level: f64,
    
    /// Alert severity thresholds
    pub alert_thresholds: AlertThresholds,
    
    /// Historical data storage configuration
    pub storage_config: StorageConfig,
    
    /// Monitoring configuration
    pub monitoring_config: MonitoringConfig,
    
    /// Notification configuration
    pub notification_config: NotificationConfig,
}

/// Alert severity thresholds for different regression levels
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AlertThresholds {
    /// Minor regression threshold (5-15% degradation)
    pub minor_threshold: f64,
    
    /// Moderate regression threshold (15-30% degradation)
    pub moderate_threshold: f64,
    
    /// Major regression threshold (30-50% degradation)
    pub major_threshold: f64,
    
    /// Critical regression threshold (>50% degradation)
    pub critical_threshold: f64,
}

/// Historical data storage configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StorageConfig {
    /// Directory for storing historical performance data
    pub data_directory: PathBuf,
    
    /// Maximum age of historical data to retain (in days)
    pub max_data_age_days: u64,
    
    /// Data compression enabled flag
    pub compression_enabled: bool,
    
    /// Backup configuration
    pub backup_enabled: bool,
    pub backup_directory: Option<PathBuf>,
}

/// Performance monitoring configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MonitoringConfig {
    /// Enable continuous monitoring
    pub continuous_monitoring_enabled: bool,
    
    /// Monitoring interval in seconds
    pub monitoring_interval_seconds: u64,
    
    /// Metrics to monitor for regression detection
    pub monitored_metrics: Vec<String>,
    
    /// Enable trend analysis and forecasting
    pub trend_analysis_enabled: bool,
    
    /// Forecasting window size for trend prediction
    pub forecasting_window: usize,
}

/// Notification configuration for regression alerts
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NotificationConfig {
    /// Enable email notifications
    pub email_enabled: bool,
    pub email_recipients: Vec<String>,
    
    /// Enable Slack notifications
    pub slack_enabled: bool,
    pub slack_webhook_url: Option<String>,
    
    /// Enable file-based notifications
    pub file_notifications_enabled: bool,
    pub notification_file_path: Option<PathBuf>,
    
    /// Enable console notifications
    pub console_notifications_enabled: bool,
}

impl Default for RegressionTestConfig {
    fn default() -> Self {
        Self {
            regression_threshold: 5.0, // 5% regression threshold
            historical_window_size: 100, // Keep 100 historical measurements
            minimum_measurements: 5, // Need at least 5 measurements for regression detection
            confidence_level: 0.95, // 95% confidence level
            alert_thresholds: AlertThresholds {
                minor_threshold: 5.0,
                moderate_threshold: 15.0,
                major_threshold: 30.0,
                critical_threshold: 50.0,
            },
            storage_config: StorageConfig {
                data_directory: PathBuf::from("performance_data"),
                max_data_age_days: 365, // Keep 1 year of data
                compression_enabled: true,
                backup_enabled: true,
                backup_directory: Some(PathBuf::from("performance_data_backup")),
            },
            monitoring_config: MonitoringConfig {
                continuous_monitoring_enabled: true,
                monitoring_interval_seconds: 3600, // Monitor every hour
                monitored_metrics: vec![
                    "prover_time_ms".to_string(),
                    "verifier_time_ms".to_string(),
                    "memory_usage_bytes".to_string(),
                    "proof_size_bytes".to_string(),
                    "throughput_ops_per_sec".to_string(),
                ],
                trend_analysis_enabled: true,
                forecasting_window: 20, // Use 20 points for forecasting
            },
            notification_config: NotificationConfig {
                email_enabled: false,
                email_recipients: Vec::new(),
                slack_enabled: false,
                slack_webhook_url: None,
                file_notifications_enabled: true,
                notification_file_path: Some(PathBuf::from("regression_alerts.log")),
                console_notifications_enabled: true,
            },
        }
    }
}

/// Historical performance measurement data point
/// 
/// Represents a single performance measurement with timestamp,
/// metrics, and metadata for regression analysis.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceMeasurement {
    /// Measurement timestamp
    pub timestamp: SystemTime,
    
    /// Unique measurement identifier
    pub measurement_id: String,
    
    /// Performance metrics measured
    pub metrics: HashMap<String, f64>,
    
    /// Test configuration used for this measurement
    pub test_config: TestConfigSnapshot,
    
    /// Hardware configuration information
    pub hardware_info: HardwareSnapshot,
    
    /// Software version information
    pub software_version: SoftwareVersion,
    
    /// Measurement metadata
    pub metadata: HashMap<String, String>,
}

/// Snapshot of test configuration for historical tracking
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestConfigSnapshot {
    /// Ring dimension used
    pub ring_dimension: usize,
    
    /// Security parameter used
    pub security_parameter: usize,
    
    /// Constraint count tested
    pub constraint_count: usize,
    
    /// Norm bound used
    pub norm_bound: i64,
    
    /// GPU acceleration enabled
    pub gpu_acceleration: bool,
    
    /// Number of benchmark iterations
    pub benchmark_iterations: usize,
}

/// Hardware configuration snapshot
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HardwareSnapshot {
    /// CPU model identifier
    pub cpu_model: String,
    
    /// Number of CPU cores
    pub cpu_cores: usize,
    
    /// CPU frequency in GHz
    pub cpu_frequency_ghz: f64,
    
    /// Memory size in GB
    pub memory_size_gb: usize,
    
    /// GPU model if available
    pub gpu_model: Option<String>,
    
    /// Operating system version
    pub os_version: String,
}

/// Software version information
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SoftwareVersion {
    /// Git commit hash
    pub commit_hash: String,
    
    /// Git branch name
    pub branch_name: String,
    
    /// Build timestamp
    pub build_timestamp: SystemTime,
    
    /// Compiler version
    pub compiler_version: String,
    
    /// Optimization flags used
    pub optimization_flags: Vec<String>,
}

/// Performance regression alert
/// 
/// Represents a detected performance regression with severity,
/// analysis, and recommended actions.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RegressionAlert {
    /// Alert unique identifier
    pub alert_id: String,
    
    /// Alert generation timestamp
    pub timestamp: SystemTime,
    
    /// Alert severity level
    pub severity: AlertSeverity,
    
    /// Metric that triggered the regression
    pub metric_name: String,
    
    /// Current measured value
    pub current_value: f64,
    
    /// Baseline value for comparison
    pub baseline_value: f64,
    
    /// Regression percentage (positive indicates degradation)
    pub regression_percentage: f64,
    
    /// Statistical confidence of the regression
    pub statistical_confidence: f64,
    
    /// Detailed regression analysis
    pub analysis: RegressionAnalysis,
    
    /// Recommended actions to address the regression
    pub recommended_actions: Vec<String>,
    
    /// Alert status (active, acknowledged, resolved)
    pub status: AlertStatus,
    
    /// Additional context and metadata
    pub context: HashMap<String, String>,
}

/// Alert severity levels
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub enum AlertSeverity {
    /// Minor performance regression (5-15% degradation)
    Minor,
    /// Moderate performance regression (15-30% degradation)
    Moderate,
    /// Major performance regression (30-50% degradation)
    Major,
    /// Critical performance regression (>50% degradation)
    Critical,
}

/// Alert status tracking
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum AlertStatus {
    /// Alert is active and requires attention
    Active,
    /// Alert has been acknowledged but not resolved
    Acknowledged,
    /// Alert has been resolved
    Resolved,
    /// Alert was determined to be a false positive
    FalsePositive,
}

/// Detailed regression analysis results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RegressionAnalysis {
    /// Trend analysis results
    pub trend_analysis: TrendAnalysis,
    
    /// Statistical analysis results
    pub statistical_analysis: StatisticalAnalysis,
    
    /// Root cause analysis hints
    pub root_cause_hints: Vec<String>,
    
    /// Historical context
    pub historical_context: HistoricalContext,
    
    /// Impact assessment
    pub impact_assessment: ImpactAssessment,
}

/// Trend analysis results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrendAnalysis {
    /// Trend direction (improving, degrading, stable)
    pub trend_direction: TrendDirection,
    
    /// Trend slope (rate of change)
    pub trend_slope: f64,
    
    /// Trend confidence (0.0 to 1.0)
    pub trend_confidence: f64,
    
    /// Forecasted values for next measurements
    pub forecasted_values: Vec<f64>,
    
    /// Trend change points detected
    pub change_points: Vec<ChangePoint>,
}

/// Trend direction classification
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum TrendDirection {
    /// Performance is improving over time
    Improving,
    /// Performance is degrading over time
    Degrading,
    /// Performance is stable with minor fluctuations
    Stable,
    /// Insufficient data to determine trend
    Unknown,
}

/// Trend change point detection
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChangePoint {
    /// Timestamp of the change point
    pub timestamp: SystemTime,
    
    /// Measurement index where change occurred
    pub measurement_index: usize,
    
    /// Magnitude of the change
    pub change_magnitude: f64,
    
    /// Confidence in change point detection
    pub confidence: f64,
    
    /// Possible causes of the change
    pub possible_causes: Vec<String>,
}

/// Statistical analysis results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StatisticalAnalysis {
    /// Mean value of recent measurements
    pub recent_mean: f64,
    
    /// Standard deviation of recent measurements
    pub recent_std_dev: f64,
    
    /// Mean value of baseline measurements
    pub baseline_mean: f64,
    
    /// Standard deviation of baseline measurements
    pub baseline_std_dev: f64,
    
    /// T-test results for mean comparison
    pub t_test_results: TTestResults,
    
    /// Effect size (Cohen's d)
    pub effect_size: f64,
    
    /// Statistical power of the test
    pub statistical_power: f64,
}

/// T-test statistical results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TTestResults {
    /// T-statistic value
    pub t_statistic: f64,
    
    /// Degrees of freedom
    pub degrees_of_freedom: usize,
    
    /// P-value for the test
    pub p_value: f64,
    
    /// Critical value for the given confidence level
    pub critical_value: f64,
    
    /// Whether the difference is statistically significant
    pub is_significant: bool,
}

/// Historical context for regression analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HistoricalContext {
    /// Number of similar regressions in the past
    pub similar_regressions_count: usize,
    
    /// Average time to resolve similar regressions
    pub average_resolution_time: Duration,
    
    /// Most common root causes for this metric
    pub common_root_causes: Vec<String>,
    
    /// Seasonal patterns detected
    pub seasonal_patterns: Vec<SeasonalPattern>,
    
    /// Correlation with other metrics
    pub metric_correlations: HashMap<String, f64>,
}

/// Seasonal pattern detection
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SeasonalPattern {
    /// Pattern type (daily, weekly, monthly)
    pub pattern_type: String,
    
    /// Pattern strength (0.0 to 1.0)
    pub strength: f64,
    
    /// Pattern phase (offset within the cycle)
    pub phase: f64,
    
    /// Pattern description
    pub description: String,
}

/// Impact assessment of the regression
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ImpactAssessment {
    /// Performance impact severity (0.0 to 1.0)
    pub performance_impact: f64,
    
    /// User experience impact assessment
    pub user_experience_impact: UserExperienceImpact,
    
    /// Resource utilization impact
    pub resource_impact: ResourceImpact,
    
    /// Business impact assessment
    pub business_impact: BusinessImpact,
    
    /// Estimated cost of the regression
    pub estimated_cost: Option<f64>,
}

/// User experience impact assessment
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserExperienceImpact {
    /// Latency impact (increased response time)
    pub latency_impact: f64,
    
    /// Throughput impact (reduced operations per second)
    pub throughput_impact: f64,
    
    /// Reliability impact (increased failure rate)
    pub reliability_impact: f64,
    
    /// Overall user experience score impact
    pub overall_ux_impact: f64,
}

/// Resource utilization impact
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResourceImpact {
    /// CPU utilization impact
    pub cpu_impact: f64,
    
    /// Memory utilization impact
    pub memory_impact: f64,
    
    /// Network utilization impact
    pub network_impact: f64,
    
    /// Storage utilization impact
    pub storage_impact: f64,
    
    /// Energy consumption impact
    pub energy_impact: f64,
}

/// Business impact assessment
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BusinessImpact {
    /// Revenue impact (potential loss)
    pub revenue_impact: f64,
    
    /// Customer satisfaction impact
    pub customer_satisfaction_impact: f64,
    
    /// Competitive advantage impact
    pub competitive_impact: f64,
    
    /// Operational efficiency impact
    pub operational_efficiency_impact: f64,
}

/// Performance regression testing framework
/// 
/// Main framework for automated performance regression testing including
/// historical data management, regression detection, alert generation,
/// and trend analysis.
pub struct RegressionTestFramework {
    /// Framework configuration
    config: RegressionTestConfig,
    
    /// Historical performance measurements
    historical_data: VecDeque<PerformanceMeasurement>,
    
    /// Active regression alerts
    active_alerts: HashMap<String, RegressionAlert>,
    
    /// Resolved alerts history
    resolved_alerts: Vec<RegressionAlert>,
    
    /// Performance trend analyzers by metric
    trend_analyzers: HashMap<String, TrendAnalyzer>,
    
    /// Statistical analyzers by metric
    statistical_analyzers: HashMap<String, StatisticalAnalyzer>,
    
    /// Notification system
    notification_system: NotificationSystem,
}

impl RegressionTestFramework {
    /// Create new regression testing framework with configuration
    /// 
    /// Initializes the framework with the specified configuration and
    /// loads any existing historical data and alerts.
    /// 
    /// # Arguments
    /// * `config` - Regression testing configuration
    /// 
    /// # Returns
    /// * New RegressionTestFramework instance
    /// 
    /// # Example
    /// ```rust
    /// let config = RegressionTestConfig::default();
    /// let framework = RegressionTestFramework::new(config)?;
    /// ```
    pub fn new(config: RegressionTestConfig) -> Result<Self> {
        // Create data directories if they don't exist
        std::fs::create_dir_all(&config.storage_config.data_directory)?;
        
        if let Some(ref backup_dir) = config.storage_config.backup_directory {
            std::fs::create_dir_all(backup_dir)?;
        }
        
        // Initialize notification system
        let notification_system = NotificationSystem::new(&config.notification_config)?;
        
        // Initialize trend analyzers for monitored metrics
        let mut trend_analyzers = HashMap::new();
        let mut statistical_analyzers = HashMap::new();
        
        for metric_name in &config.monitoring_config.monitored_metrics {
            trend_analyzers.insert(
                metric_name.clone(),
                TrendAnalyzer::new(config.monitoring_config.forecasting_window)
            );
            
            statistical_analyzers.insert(
                metric_name.clone(),
                StatisticalAnalyzer::new(config.confidence_level)
            );
        }
        
        let mut framework = Self {
            config,
            historical_data: VecDeque::new(),
            active_alerts: HashMap::new(),
            resolved_alerts: Vec::new(),
            trend_analyzers,
            statistical_analyzers,
            notification_system,
        };
        
        // Load existing historical data
        framework.load_historical_data()?;
        
        // Load existing alerts
        framework.load_alerts()?;
        
        Ok(framework)
    }
    
    /// Add new performance measurement to the framework
    /// 
    /// Adds a new performance measurement to the historical data and
    /// triggers regression analysis if sufficient data is available.
    /// 
    /// # Arguments
    /// * `measurement` - New performance measurement to add
    /// 
    /// # Returns
    /// * Vector of regression alerts generated (if any)
    /// 
    /// # Example
    /// ```rust
    /// let measurement = PerformanceMeasurement {
    ///     timestamp: SystemTime::now(),
    ///     measurement_id: "test_001".to_string(),
    ///     metrics: [("prover_time_ms".to_string(), 1250.0)].iter().cloned().collect(),
    ///     // ... other fields
    /// };
    /// 
    /// let alerts = framework.add_measurement(measurement)?;
    /// ```
    pub fn add_measurement(&mut self, measurement: PerformanceMeasurement) -> Result<Vec<RegressionAlert>> {
        println!("Adding performance measurement: {}", measurement.measurement_id);
        
        // Add measurement to historical data
        self.historical_data.push_back(measurement.clone());
        
        // Maintain historical window size
        while self.historical_data.len() > self.config.historical_window_size {
            self.historical_data.pop_front();
        }
        
        // Update trend analyzers with new data
        for (metric_name, metric_value) in &measurement.metrics {
            if let Some(analyzer) = self.trend_analyzers.get_mut(metric_name) {
                analyzer.add_measurement(measurement.timestamp, *metric_value)?;
            }
            
            if let Some(analyzer) = self.statistical_analyzers.get_mut(metric_name) {
                analyzer.add_measurement(*metric_value)?;
            }
        }
        
        // Perform regression analysis if we have sufficient data
        let mut new_alerts = Vec::new();
        
        if self.historical_data.len() >= self.config.minimum_measurements {
            new_alerts = self.analyze_regressions(&measurement)?;
        }
        
        // Save updated historical data
        self.save_historical_data()?;
        
        // Process any new alerts
        for alert in &new_alerts {
            self.process_new_alert(alert.clone())?;
        }
        
        Ok(new_alerts)
    }
    
    /// Analyze performance regressions for the latest measurement
    /// 
    /// Performs comprehensive regression analysis including statistical
    /// testing, trend analysis, and impact assessment.
    fn analyze_regressions(&mut self, latest_measurement: &PerformanceMeasurement) -> Result<Vec<RegressionAlert>> {
        let mut alerts = Vec::new();
        
        // Analyze each metric for regressions
        for (metric_name, &current_value) in &latest_measurement.metrics {
            if let Some(alert) = self.analyze_metric_regression(metric_name, current_value, latest_measurement)? {
                alerts.push(alert);
            }
        }
        
        Ok(alerts)
    }
    
    /// Analyze regression for a specific metric
    /// 
    /// Performs detailed regression analysis for a single metric including
    /// statistical significance testing and trend analysis.
    fn analyze_metric_regression(
        &mut self,
        metric_name: &str,
        current_value: f64,
        latest_measurement: &PerformanceMeasurement
    ) -> Result<Option<RegressionAlert>> {
        // Get historical values for this metric
        let historical_values: Vec<f64> = self.historical_data
            .iter()
            .filter_map(|m| m.metrics.get(metric_name))
            .copied()
            .collect();
        
        if historical_values.len() < self.config.minimum_measurements {
            return Ok(None); // Insufficient data for analysis
        }
        
        // Calculate baseline statistics (excluding the latest measurement)
        let baseline_values = &historical_values[..historical_values.len() - 1];
        let baseline_mean = baseline_values.iter().sum::<f64>() / baseline_values.len() as f64;
        
        // Calculate regression percentage
        let regression_percentage = ((current_value - baseline_mean) / baseline_mean) * 100.0;
        
        // Check if regression exceeds threshold
        if regression_percentage.abs() < self.config.regression_threshold {
            return Ok(None); // No significant regression
        }
        
        // Determine alert severity
        let severity = self.determine_alert_severity(regression_percentage.abs());
        
        // Perform statistical analysis
        let statistical_analysis = if let Some(analyzer) = self.statistical_analyzers.get(metric_name) {
            analyzer.analyze_regression(current_value, baseline_values)?
        } else {
            return Ok(None);
        };
        
        // Check statistical significance
        if !statistical_analysis.t_test_results.is_significant {
            return Ok(None); // Not statistically significant
        }
        
        // Perform trend analysis
        let trend_analysis = if let Some(analyzer) = self.trend_analyzers.get(metric_name) {
            analyzer.analyze_trend()?
        } else {
            return Ok(None);
        };
        
        // Generate regression analysis
        let analysis = RegressionAnalysis {
            trend_analysis,
            statistical_analysis,
            root_cause_hints: self.generate_root_cause_hints(metric_name, regression_percentage),
            historical_context: self.generate_historical_context(metric_name)?,
            impact_assessment: self.assess_regression_impact(metric_name, regression_percentage)?,
        };
        
        // Generate alert
        let alert_id = format!("{}_{}", 
                              metric_name, 
                              latest_measurement.timestamp.duration_since(UNIX_EPOCH)
                                  .unwrap_or_default().as_secs());
        
        let alert = RegressionAlert {
            alert_id,
            timestamp: SystemTime::now(),
            severity,
            metric_name: metric_name.to_string(),
            current_value,
            baseline_value: baseline_mean,
            regression_percentage,
            statistical_confidence: 1.0 - analysis.statistical_analysis.t_test_results.p_value,
            analysis,
            recommended_actions: self.generate_recommended_actions(metric_name, regression_percentage),
            status: AlertStatus::Active,
            context: self.generate_alert_context(latest_measurement),
        };
        
        Ok(Some(alert))
    }
    
    /// Determine alert severity based on regression percentage
    fn determine_alert_severity(&self, regression_percentage: f64) -> AlertSeverity {
        if regression_percentage >= self.config.alert_thresholds.critical_threshold {
            AlertSeverity::Critical
        } else if regression_percentage >= self.config.alert_thresholds.major_threshold {
            AlertSeverity::Major
        } else if regression_percentage >= self.config.alert_thresholds.moderate_threshold {
            AlertSeverity::Moderate
        } else {
            AlertSeverity::Minor
        }
    }
    
    /// Generate root cause hints for the regression
    fn generate_root_cause_hints(&self, metric_name: &str, regression_percentage: f64) -> Vec<String> {
        let mut hints = Vec::new();
        
        // Metric-specific hints
        match metric_name {
            name if name.contains("prover_time") => {
                hints.push("Check for changes in prover algorithm implementation".to_string());
                hints.push("Verify NTT optimization is functioning correctly".to_string());
                hints.push("Check for memory allocation inefficiencies".to_string());
                hints.push("Verify GPU acceleration is working if enabled".to_string());
            },
            name if name.contains("verifier_time") => {
                hints.push("Check for changes in verification algorithm".to_string());
                hints.push("Verify sumcheck optimization is working".to_string());
                hints.push("Check for proof parsing inefficiencies".to_string());
            },
            name if name.contains("memory_usage") => {
                hints.push("Check for memory leaks in recent changes".to_string());
                hints.push("Verify memory pooling is functioning correctly".to_string());
                hints.push("Check for increased allocation frequency".to_string());
            },
            name if name.contains("proof_size") => {
                hints.push("Check for changes in proof compression".to_string());
                hints.push("Verify commitment scheme optimization".to_string());
                hints.push("Check for serialization inefficiencies".to_string());
            },
            _ => {
                hints.push("Review recent code changes that may affect this metric".to_string());
                hints.push("Check for configuration changes".to_string());
                hints.push("Verify test environment consistency".to_string());
            }
        }
        
        // Severity-specific hints
        if regression_percentage > 50.0 {
            hints.push("URGENT: This is a critical regression requiring immediate attention".to_string());
            hints.push("Consider reverting recent changes if root cause is not immediately clear".to_string());
        } else if regression_percentage > 25.0 {
            hints.push("This is a significant regression that should be prioritized".to_string());
        }
        
        hints
    }
    
    /// Generate historical context for the regression
    fn generate_historical_context(&self, metric_name: &str) -> Result<HistoricalContext> {
        // Count similar regressions in historical data
        let similar_regressions_count = self.resolved_alerts
            .iter()
            .filter(|alert| alert.metric_name == metric_name && alert.regression_percentage > 0.0)
            .count();
        
        // Calculate average resolution time (simplified)
        let average_resolution_time = Duration::from_hours(24); // Placeholder
        
        // Generate common root causes based on historical patterns
        let common_root_causes = vec![
            "Algorithm optimization regression".to_string(),
            "Memory management inefficiency".to_string(),
            "Configuration parameter changes".to_string(),
            "Compiler optimization changes".to_string(),
        ];
        
        // Placeholder for seasonal patterns and correlations
        let seasonal_patterns = Vec::new();
        let metric_correlations = HashMap::new();
        
        Ok(HistoricalContext {
            similar_regressions_count,
            average_resolution_time,
            common_root_causes,
            seasonal_patterns,
            metric_correlations,
        })
    }
    
    /// Assess the impact of the regression
    fn assess_regression_impact(&self, metric_name: &str, regression_percentage: f64) -> Result<ImpactAssessment> {
        // Calculate performance impact (normalized to 0.0-1.0)
        let performance_impact = (regression_percentage / 100.0).min(1.0);
        
        // Assess user experience impact
        let user_experience_impact = UserExperienceImpact {
            latency_impact: if metric_name.contains("time") { performance_impact } else { 0.0 },
            throughput_impact: if metric_name.contains("throughput") { performance_impact } else { 0.0 },
            reliability_impact: 0.0, // Would be calculated based on failure rates
            overall_ux_impact: performance_impact * 0.5, // Simplified calculation
        };
        
        // Assess resource impact
        let resource_impact = ResourceImpact {
            cpu_impact: if metric_name.contains("time") { performance_impact } else { 0.0 },
            memory_impact: if metric_name.contains("memory") { performance_impact } else { 0.0 },
            network_impact: 0.0,
            storage_impact: if metric_name.contains("proof_size") { performance_impact } else { 0.0 },
            energy_impact: performance_impact * 0.3, // Simplified calculation
        };
        
        // Assess business impact
        let business_impact = BusinessImpact {
            revenue_impact: performance_impact * 0.1, // Simplified calculation
            customer_satisfaction_impact: performance_impact * 0.2,
            competitive_impact: performance_impact * 0.3,
            operational_efficiency_impact: performance_impact,
        };
        
        Ok(ImpactAssessment {
            performance_impact,
            user_experience_impact,
            resource_impact,
            business_impact,
            estimated_cost: None, // Would be calculated based on business metrics
        })
    }
    
    /// Generate recommended actions for addressing the regression
    fn generate_recommended_actions(&self, metric_name: &str, regression_percentage: f64) -> Vec<String> {
        let mut actions = Vec::new();
        
        // Immediate actions based on severity
        if regression_percentage > 50.0 {
            actions.push("IMMEDIATE: Investigate and address this critical regression".to_string());
            actions.push("Consider reverting recent changes if root cause is not clear".to_string());
            actions.push("Escalate to senior engineering team".to_string());
        } else if regression_percentage > 25.0 {
            actions.push("HIGH PRIORITY: Investigate this major regression within 24 hours".to_string());
            actions.push("Review recent commits and changes".to_string());
        } else {
            actions.push("Investigate this regression within the next sprint".to_string());
        }
        
        // Metric-specific actions
        match metric_name {
            name if name.contains("prover_time") => {
                actions.push("Profile prover execution to identify bottlenecks".to_string());
                actions.push("Check NTT and polynomial multiplication optimizations".to_string());
                actions.push("Verify GPU acceleration is functioning correctly".to_string());
            },
            name if name.contains("verifier_time") => {
                actions.push("Profile verifier execution to identify bottlenecks".to_string());
                actions.push("Check sumcheck and proof verification optimizations".to_string());
            },
            name if name.contains("memory_usage") => {
                actions.push("Run memory profiler to identify leaks or inefficiencies".to_string());
                actions.push("Check memory allocation patterns and pooling".to_string());
            },
            _ => {
                actions.push("Run comprehensive profiling to identify the root cause".to_string());
            }
        }
        
        // General actions
        actions.push("Update regression test baselines if the change is intentional".to_string());
        actions.push("Document the investigation and resolution process".to_string());
        
        actions
    }
    
    /// Generate alert context information
    fn generate_alert_context(&self, measurement: &PerformanceMeasurement) -> HashMap<String, String> {
        let mut context = HashMap::new();
        
        context.insert("measurement_id".to_string(), measurement.measurement_id.clone());
        context.insert("software_version".to_string(), measurement.software_version.commit_hash.clone());
        context.insert("hardware_config".to_string(), measurement.hardware_info.cpu_model.clone());
        context.insert("test_config".to_string(), format!("ring_dim_{}_sec_{}", 
                      measurement.test_config.ring_dimension, 
                      measurement.test_config.security_parameter));
        
        // Add any additional metadata
        for (key, value) in &measurement.metadata {
            context.insert(key.clone(), value.clone());
        }
        
        context
    }
    
    /// Process a new regression alert
    fn process_new_alert(&mut self, alert: RegressionAlert) -> Result<()> {
        println!("Processing new regression alert: {} ({})", alert.alert_id, alert.severity);
        
        // Add to active alerts
        self.active_alerts.insert(alert.alert_id.clone(), alert.clone());
        
        // Send notifications
        self.notification_system.send_alert_notification(&alert)?;
        
        // Save alerts to persistent storage
        self.save_alerts()?;
        
        Ok(())
    }
    
    /// Load historical performance data from storage
    fn load_historical_data(&mut self) -> Result<()> {
        let data_file = self.config.storage_config.data_directory.join("historical_data.json");
        
        if data_file.exists() {
            println!("Loading historical performance data from {:?}", data_file);
            
            let file = File::open(data_file)?;
            let reader = BufReader::new(file);
            
            // In a real implementation, this would deserialize JSON data
            // For now, we'll initialize with empty data
            self.historical_data = VecDeque::new();
            
            println!("Loaded {} historical measurements", self.historical_data.len());
        } else {
            println!("No historical data found, starting with empty dataset");
        }
        
        Ok(())
    }
    
    /// Save historical performance data to storage
    fn save_historical_data(&self) -> Result<()> {
        let data_file = self.config.storage_config.data_directory.join("historical_data.json");
        
        // In a real implementation, this would serialize the data to JSON
        // For now, we'll just create a placeholder file
        let mut file = File::create(data_file)?;
        writeln!(file, "# Historical performance data")?;
        writeln!(file, "# {} measurements stored", self.historical_data.len())?;
        
        Ok(())
    }
    
    /// Load existing alerts from storage
    fn load_alerts(&mut self) -> Result<()> {
        let alerts_file = self.config.storage_config.data_directory.join("alerts.json");
        
        if alerts_file.exists() {
            println!("Loading existing alerts from {:?}", alerts_file);
            
            // In a real implementation, this would deserialize alert data
            // For now, we'll initialize with empty alerts
            self.active_alerts = HashMap::new();
            self.resolved_alerts = Vec::new();
            
            println!("Loaded {} active alerts and {} resolved alerts", 
                     self.active_alerts.len(), self.resolved_alerts.len());
        }
        
        Ok(())
    }
    
    /// Save alerts to persistent storage
    fn save_alerts(&self) -> Result<()> {
        let alerts_file = self.config.storage_config.data_directory.join("alerts.json");
        
        // In a real implementation, this would serialize alerts to JSON
        let mut file = File::create(alerts_file)?;
        writeln!(file, "# Regression alerts")?;
        writeln!(file, "# {} active alerts", self.active_alerts.len())?;
        writeln!(file, "# {} resolved alerts", self.resolved_alerts.len())?;
        
        Ok(())
    }
    
    /// Get current active alerts
    pub fn get_active_alerts(&self) -> &HashMap<String, RegressionAlert> {
        &self.active_alerts
    }
    
    /// Acknowledge an alert
    pub fn acknowledge_alert(&mut self, alert_id: &str) -> Result<()> {
        if let Some(alert) = self.active_alerts.get_mut(alert_id) {
            alert.status = AlertStatus::Acknowledged;
            self.save_alerts()?;
            println!("Alert {} acknowledged", alert_id);
        }
        Ok(())
    }
    
    /// Resolve an alert
    pub fn resolve_alert(&mut self, alert_id: &str) -> Result<()> {
        if let Some(mut alert) = self.active_alerts.remove(alert_id) {
            alert.status = AlertStatus::Resolved;
            self.resolved_alerts.push(alert);
            self.save_alerts()?;
            println!("Alert {} resolved", alert_id);
        }
        Ok(())
    }
    
    /// Generate regression testing report
    pub fn generate_report(&self) -> Result<String> {
        let mut report = String::new();
        
        report.push_str("# Performance Regression Testing Report\n\n");
        report.push_str(&format!("**Generated:** {:?}\n", SystemTime::now()));
        report.push_str(&format!("**Historical Measurements:** {}\n", self.historical_data.len()));
        report.push_str(&format!("**Active Alerts:** {}\n", self.active_alerts.len()));
        report.push_str(&format!("**Resolved Alerts:** {}\n\n", self.resolved_alerts.len()));
        
        // Active alerts summary
        if !self.active_alerts.is_empty() {
            report.push_str("## Active Regression Alerts\n\n");
            
            for (alert_id, alert) in &self.active_alerts {
                report.push_str(&format!("### Alert: {} ({:?})\n", alert_id, alert.severity));
                report.push_str(&format!("- **Metric:** {}\n", alert.metric_name));
                report.push_str(&format!("- **Regression:** {:.2}%\n", alert.regression_percentage));
                report.push_str(&format!("- **Current Value:** {:.2}\n", alert.current_value));
                report.push_str(&format!("- **Baseline Value:** {:.2}\n", alert.baseline_value));
                report.push_str(&format!("- **Confidence:** {:.2}%\n", alert.statistical_confidence * 100.0));
                report.push_str("\n**Recommended Actions:**\n");
                for action in &alert.recommended_actions {
                    report.push_str(&format!("- {}\n", action));
                }
                report.push_str("\n");
            }
        } else {
            report.push_str("## No Active Regression Alerts\n\n");
            report.push_str("âœ… All performance metrics are within acceptable ranges.\n\n");
        }
        
        // Performance trends summary
        report.push_str("## Performance Trends\n\n");
        for (metric_name, analyzer) in &self.trend_analyzers {
            if let Ok(trend) = analyzer.analyze_trend() {
                report.push_str(&format!("### {}\n", metric_name));
                report.push_str(&format!("- **Trend Direction:** {:?}\n", trend.trend_direction));
                report.push_str(&format!("- **Trend Confidence:** {:.2}%\n", trend.trend_confidence * 100.0));
                report.push_str(&format!("- **Trend Slope:** {:.4}\n", trend.trend_slope));
                report.push_str("\n");
            }
        }
        
        Ok(report)
    }
}

/// Trend analyzer for performance metrics
/// 
/// Analyzes performance trends over time including trend direction,
/// change point detection, and forecasting.
pub struct TrendAnalyzer {
    /// Historical data points (timestamp, value)
    data_points: VecDeque<(SystemTime, f64)>,
    
    /// Maximum number of data points to maintain
    max_data_points: usize,
}

impl TrendAnalyzer {
    /// Create new trend analyzer
    pub fn new(max_data_points: usize) -> Self {
        Self {
            data_points: VecDeque::new(),
            max_data_points,
        }
    }
    
    /// Add new measurement to the analyzer
    pub fn add_measurement(&mut self, timestamp: SystemTime, value: f64) -> Result<()> {
        self.data_points.push_back((timestamp, value));
        
        // Maintain maximum data points
        while self.data_points.len() > self.max_data_points {
            self.data_points.pop_front();
        }
        
        Ok(())
    }
    
    /// Analyze trend in the data
    pub fn analyze_trend(&self) -> Result<TrendAnalysis> {
        if self.data_points.len() < 3 {
            return Ok(TrendAnalysis {
                trend_direction: TrendDirection::Unknown,
                trend_slope: 0.0,
                trend_confidence: 0.0,
                forecasted_values: Vec::new(),
                change_points: Vec::new(),
            });
        }
        
        // Convert timestamps to numeric values for analysis
        let start_time = self.data_points[0].0;
        let data: Vec<(f64, f64)> = self.data_points
            .iter()
            .map(|(timestamp, value)| {
                let elapsed = timestamp.duration_since(start_time)
                    .unwrap_or_default()
                    .as_secs_f64();
                (elapsed, *value)
            })
            .collect();
        
        // Calculate trend slope using linear regression
        let (slope, r_squared) = self.calculate_linear_regression(&data);
        
        // Determine trend direction
        let trend_direction = if slope.abs() < 0.001 {
            TrendDirection::Stable
        } else if slope > 0.0 {
            TrendDirection::Degrading // Assuming higher values are worse
        } else {
            TrendDirection::Improving
        };
        
        // Generate forecasted values
        let forecasted_values = self.generate_forecasts(&data, slope, 5);
        
        // Detect change points (simplified)
        let change_points = self.detect_change_points(&data);
        
        Ok(TrendAnalysis {
            trend_direction,
            trend_slope: slope,
            trend_confidence: r_squared,
            forecasted_values,
            change_points,
        })
    }
    
    /// Calculate linear regression slope and R-squared
    fn calculate_linear_regression(&self, data: &[(f64, f64)]) -> (f64, f64) {
        if data.len() < 2 {
            return (0.0, 0.0);
        }
        
        let n = data.len() as f64;
        let sum_x: f64 = data.iter().map(|(x, _)| x).sum();
        let sum_y: f64 = data.iter().map(|(_, y)| y).sum();
        let sum_xy: f64 = data.iter().map(|(x, y)| x * y).sum();
        let sum_x2: f64 = data.iter().map(|(x, _)| x * x).sum();
        
        let slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x);
        
        // Calculate R-squared
        let mean_y = sum_y / n;
        let ss_tot: f64 = data.iter().map(|(_, y)| (y - mean_y).powi(2)).sum();
        let intercept = (sum_y - slope * sum_x) / n;
        let ss_res: f64 = data.iter()
            .map(|(x, y)| {
                let predicted = slope * x + intercept;
                (y - predicted).powi(2)
            })
            .sum();
        
        let r_squared = if ss_tot > 0.0 { 1.0 - ss_res / ss_tot } else { 0.0 };
        
        (slope, r_squared)
    }
    
    /// Generate forecasted values
    fn generate_forecasts(&self, data: &[(f64, f64)], slope: f64, num_forecasts: usize) -> Vec<f64> {
        if data.is_empty() {
            return Vec::new();
        }
        
        let last_point = data.last().unwrap();
        let mut forecasts = Vec::new();
        
        for i in 1..=num_forecasts {
            let forecast_x = last_point.0 + (i as f64 * 3600.0); // Assume hourly intervals
            let forecast_y = last_point.1 + slope * (forecast_x - last_point.0);
            forecasts.push(forecast_y);
        }
        
        forecasts
    }
    
    /// Detect change points in the data (simplified implementation)
    fn detect_change_points(&self, data: &[(f64, f64)]) -> Vec<ChangePoint> {
        let mut change_points = Vec::new();
        
        if data.len() < 6 {
            return change_points; // Need sufficient data for change point detection
        }
        
        // Simple change point detection using moving averages
        let window_size = 3;
        for i in window_size..(data.len() - window_size) {
            let before_avg: f64 = data[(i - window_size)..i].iter().map(|(_, y)| y).sum::<f64>() / window_size as f64;
            let after_avg: f64 = data[(i + 1)..(i + 1 + window_size)].iter().map(|(_, y)| y).sum::<f64>() / window_size as f64;
            
            let change_magnitude = (after_avg - before_avg).abs();
            let relative_change = change_magnitude / before_avg.abs().max(1.0);
            
            // Threshold for change point detection
            if relative_change > 0.2 { // 20% change threshold
                let timestamp = SystemTime::UNIX_EPOCH + Duration::from_secs_f64(data[i].0);
                
                change_points.push(ChangePoint {
                    timestamp,
                    measurement_index: i,
                    change_magnitude,
                    confidence: relative_change.min(1.0),
                    possible_causes: vec![
                        "Algorithm change".to_string(),
                        "Configuration update".to_string(),
                        "Hardware change".to_string(),
                    ],
                });
            }
        }
        
        change_points
    }
}

/// Statistical analyzer for regression detection
/// 
/// Performs statistical analysis for regression detection including
/// t-tests, effect size calculation, and significance testing.
pub struct StatisticalAnalyzer {
    /// Historical measurements
    measurements: VecDeque<f64>,
    
    /// Confidence level for statistical tests
    confidence_level: f64,
}

impl StatisticalAnalyzer {
    /// Create new statistical analyzer
    pub fn new(confidence_level: f64) -> Self {
        Self {
            measurements: VecDeque::new(),
            confidence_level,
        }
    }
    
    /// Add new measurement
    pub fn add_measurement(&mut self, value: f64) -> Result<()> {
        self.measurements.push_back(value);
        Ok(())
    }
    
    /// Analyze regression using statistical methods
    pub fn analyze_regression(&self, current_value: f64, baseline_values: &[f64]) -> Result<StatisticalAnalysis> {
        if baseline_values.len() < 2 {
            return Err(LatticeFoldError::InsufficientData("Need at least 2 baseline values for statistical analysis".to_string()));
        }
        
        // Calculate baseline statistics
        let baseline_mean = baseline_values.iter().sum::<f64>() / baseline_values.len() as f64;
        let baseline_variance = baseline_values.iter()
            .map(|x| (x - baseline_mean).powi(2))
            .sum::<f64>() / (baseline_values.len() - 1) as f64;
        let baseline_std_dev = baseline_variance.sqrt();
        
        // Recent measurements (including current)
        let recent_values = vec![current_value];
        let recent_mean = current_value;
        let recent_std_dev = 0.0; // Single value
        
        // Perform t-test
        let t_test_results = self.perform_t_test(
            recent_mean, recent_std_dev, recent_values.len(),
            baseline_mean, baseline_std_dev, baseline_values.len()
        )?;
        
        // Calculate effect size (Cohen's d)
        let pooled_std_dev = ((baseline_variance * (baseline_values.len() - 1) as f64) / 
                             (baseline_values.len() + recent_values.len() - 2) as f64).sqrt();
        let effect_size = (recent_mean - baseline_mean) / pooled_std_dev;
        
        // Calculate statistical power (simplified)
        let statistical_power = if t_test_results.is_significant { 0.8 } else { 0.2 };
        
        Ok(StatisticalAnalysis {
            recent_mean,
            recent_std_dev,
            baseline_mean,
            baseline_std_dev,
            t_test_results,
            effect_size,
            statistical_power,
        })
    }
    
    /// Perform t-test for mean comparison
    fn perform_t_test(
        &self,
        mean1: f64, std_dev1: f64, n1: usize,
        mean2: f64, std_dev2: f64, n2: usize
    ) -> Result<TTestResults> {
        // Welch's t-test for unequal variances
        let variance1 = std_dev1.powi(2);
        let variance2 = std_dev2.powi(2);
        
        let standard_error = (variance1 / n1 as f64 + variance2 / n2 as f64).sqrt();
        let t_statistic = (mean1 - mean2) / standard_error;
        
        // Calculate degrees of freedom (Welch-Satterthwaite equation)
        let degrees_of_freedom = if variance1 > 0.0 && variance2 > 0.0 {
            let numerator = (variance1 / n1 as f64 + variance2 / n2 as f64).powi(2);
            let denominator = (variance1 / n1 as f64).powi(2) / (n1 - 1) as f64 +
                             (variance2 / n2 as f64).powi(2) / (n2 - 1) as f64;
            (numerator / denominator) as usize
        } else {
            n1 + n2 - 2
        };
        
        // Critical value for two-tailed test (approximation)
        let alpha = 1.0 - self.confidence_level;
        let critical_value = 1.96; // Approximation for large samples
        
        // P-value calculation (simplified)
        let p_value = if t_statistic.abs() > critical_value {
            alpha / 2.0 // Significant
        } else {
            alpha * 2.0 // Not significant
        };
        
        let is_significant = t_statistic.abs() > critical_value;
        
        Ok(TTestResults {
            t_statistic,
            degrees_of_freedom,
            p_value,
            critical_value,
            is_significant,
        })
    }
}

/// Notification system for regression alerts
/// 
/// Handles sending notifications through various channels including
/// email, Slack, file-based notifications, and console output.
pub struct NotificationSystem {
    /// Notification configuration
    config: NotificationConfig,
}

impl NotificationSystem {
    /// Create new notification system
    pub fn new(config: &NotificationConfig) -> Result<Self> {
        Ok(Self {
            config: config.clone(),
        })
    }
    
    /// Send alert notification through configured channels
    pub fn send_alert_notification(&self, alert: &RegressionAlert) -> Result<()> {
        // Console notification
        if self.config.console_notifications_enabled {
            self.send_console_notification(alert)?;
        }
        
        // File notification
        if self.config.file_notifications_enabled {
            self.send_file_notification(alert)?;
        }
        
        // Email notification (placeholder)
        if self.config.email_enabled {
            self.send_email_notification(alert)?;
        }
        
        // Slack notification (placeholder)
        if self.config.slack_enabled {
            self.send_slack_notification(alert)?;
        }
        
        Ok(())
    }
    
    /// Send console notification
    fn send_console_notification(&self, alert: &RegressionAlert) -> Result<()> {
        println!("ðŸš¨ PERFORMANCE REGRESSION ALERT ðŸš¨");
        println!("Alert ID: {}", alert.alert_id);
        println!("Severity: {:?}", alert.severity);
        println!("Metric: {}", alert.metric_name);
        println!("Regression: {:.2}%", alert.regression_percentage);
        println!("Current Value: {:.2}", alert.current_value);
        println!("Baseline Value: {:.2}", alert.baseline_value);
        println!("Confidence: {:.2}%", alert.statistical_confidence * 100.0);
        println!("Recommended Actions:");
        for action in &alert.recommended_actions {
            println!("  - {}", action);
        }
        println!();
        
        Ok(())
    }
    
    /// Send file-based notification
    fn send_file_notification(&self, alert: &RegressionAlert) -> Result<()> {
        if let Some(ref file_path) = self.config.notification_file_path {
            let mut file = OpenOptions::new()
                .create(true)
                .append(true)
                .open(file_path)?;
            
            writeln!(file, "[{}] REGRESSION ALERT: {} ({:?})", 
                    chrono::Utc::now().format("%Y-%m-%d %H:%M:%S"),
                    alert.alert_id, alert.severity)?;
            writeln!(file, "  Metric: {} | Regression: {:.2}% | Confidence: {:.2}%",
                    alert.metric_name, alert.regression_percentage, 
                    alert.statistical_confidence * 100.0)?;
            writeln!(file, "  Current: {:.2} | Baseline: {:.2}",
                    alert.current_value, alert.baseline_value)?;
            writeln!(file)?;
        }
        
        Ok(())
    }
    
    /// Send email notification (placeholder)
    fn send_email_notification(&self, alert: &RegressionAlert) -> Result<()> {
        // In a real implementation, this would send actual emails
        println!("ðŸ“§ Email notification sent for alert: {}", alert.alert_id);
        Ok(())
    }
    
    /// Send Slack notification (placeholder)
    fn send_slack_notification(&self, alert: &RegressionAlert) -> Result<()> {
        // In a real implementation, this would send Slack messages
        println!("ðŸ’¬ Slack notification sent for alert: {}", alert.alert_id);
        Ok(())
    }
}

// Helper trait for duration creation
trait DurationExt {
    fn from_hours(hours: u64) -> Duration;
}

impl DurationExt for Duration {
    fn from_hours(hours: u64) -> Duration {
        Duration::from_secs(hours * 3600)
    }
}

// Placeholder for chrono dependency
mod chrono {
    pub struct Utc;
    
    impl Utc {
        pub fn now() -> DateTime {
            DateTime
        }
    }
    
    pub struct DateTime;
    
    impl DateTime {
        pub fn format(&self, _format: &str) -> String {
            "2024-01-01 12:00:00".to_string()
        }
    }
}